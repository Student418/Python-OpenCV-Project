{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd327e0c-db9b-424a-83fc-d783bf4f9018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import dlib\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "\n",
    "def detect_faces(frame, face_detection):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(frame_rgb)\n",
    "\n",
    "    if results.detections:\n",
    "        return True, results.detections\n",
    "    else:\n",
    "        return False, None\n",
    "\n",
    "def detect_hands(frame, hand_detection):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hand_detection.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        return True, results.multi_hand_landmarks\n",
    "    else:\n",
    "        return False, None\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)  \n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        return\n",
    "\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "    font_1 = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    class VideoStream:\n",
    "        def __init__(self, stream):\n",
    "            self.video = cv2.VideoCapture(stream)\n",
    "            self.video.set(cv2.CAP_PROP_FPS, 60)\n",
    "\n",
    "            if not self.video.isOpened():\n",
    "                print(\"Can't access the webcam stream.\")\n",
    "                exit(0)\n",
    "            \n",
    "            self.grabbed, self.frame = self.video.read()\n",
    "            self.stopped = True\n",
    "            self.thread = Thread(target=self.update)\n",
    "            self.thread.daemon = True\n",
    "        \n",
    "        def start(self):\n",
    "            self.stopped = False\n",
    "            self.thread.start()\n",
    "\n",
    "        def update(self):\n",
    "            while True:\n",
    "                if self.stopped:\n",
    "                    break\n",
    "            \n",
    "                self.grabbed, self.frame = self.video.read()\n",
    "            self.video.release()\n",
    "\n",
    "        def read(self):\n",
    "            return self.frame\n",
    "\n",
    "        def stop(self):\n",
    "            self.stopped = True\n",
    "\n",
    "    video_stream = VideoStream(stream=0)\n",
    "    video_stream.start()\n",
    "\n",
    "    cv2.namedWindow(\"Face Detection\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    no_detection_start_time = None\n",
    "    detection_threshold = 5 \n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Couldn't read frame.\")\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1) \n",
    "\n",
    "        detected_face, detections = detect_faces(frame, face_detection)\n",
    "        detected_hand, hand_landmarks = detect_hands(frame, hands)\n",
    "\n",
    "        if detected_face and not detected_hand:\n",
    "            display_text = \"Sitting\"\n",
    "            no_detection_start_time = None\n",
    "        elif detected_hand:\n",
    "            display_text = \"Namastey\"\n",
    "            no_detection_start_time = None\n",
    "        else:\n",
    "            if no_detection_start_time is None:\n",
    "                no_detection_start_time = time.time()\n",
    "            elif time.time() - no_detection_start_time > detection_threshold:\n",
    "                display_text = \"Head Down\"\n",
    "            else:\n",
    "                display_text = \"Neutral\"\n",
    "\n",
    "        if display_text:\n",
    "            cv2.putText(frame, display_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        if video_stream.stopped:\n",
    "            break\n",
    "        else:\n",
    "            frame_display = frame.copy()\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            rects = detector(gray, 1)\n",
    "\n",
    "            for i, face_rect in enumerate(rects):\n",
    "                left = face_rect.left()\n",
    "                top = face_rect.top()\n",
    "                width = face_rect.right() - left\n",
    "                height = face_rect.bottom() - top\n",
    "\n",
    "                cv2.rectangle(frame_display, (left, top), (left+width, top+height), (0, 255, 0), 2)\n",
    "                cv2.putText(frame_display, f\"Face {i+1}\", (left - 10, top - 10), font_1, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                frame_crop = frame[top + 10:top+height-100, left + 30: left+width - 20]\n",
    "                \n",
    "                if frame_crop.size > 0:\n",
    "                    img_blur = cv2.GaussianBlur(np.array(frame_crop), (5,5), sigmaX=1.7, sigmaY=1.7)\n",
    "                    edges = cv2.Canny(image=img_blur, threshold1=100, threshold2=200)\n",
    "\n",
    "                   \n",
    "                    cv2.rectangle(frame_display, (left, top+height), (left+width, top+height+40), (0, 255, 0), cv2.FILLED)\n",
    "                    cv2.putText(frame_display, \"Face Detected\", (left+10, top+height+20), font_1, 0.65, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow(\"Face Detection\", frame_display)\n",
    "\n",
    "        delay = 0.1\n",
    "        time.sleep(delay)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_stream.stop()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c619e9bd-4edf-4785-9a89-4519d7a412b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
